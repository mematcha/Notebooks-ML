{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation Tour - Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Release Blog](https://pytorch.org/blog/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a popular open-source machine learning library built on top of the Torch library. It's particularly well-suited for deep learning applications due to its dynamic computational graph, which allows for more flexible and intuitive development.\n",
    "\n",
    "## Key Features and Benefits:\n",
    "\n",
    "- `Dynamic Computational Graph`: Unlike static frameworks, PyTorch allows you to define and modify the computational graph on the fly, making it easier to experiment and debug.\n",
    "- `Tensor Operations`: PyTorch provides efficient tensor operations for numerical computations, essential for deep learning models.\n",
    "- `Autograd`: Automatically calculates gradients for backpropagation, simplifying the training process.\n",
    "- `CUDA Integration`: Supports GPU acceleration for faster training and inference, especially on large datasets.\n",
    "- `Community and Ecosystem`: A large and active community contributes to PyTorch's development and provides a wealth of resources, including tutorials, libraries, and tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Family of Libraries\n",
    "\n",
    "PyTorch has a growing ecosystem of libraries that extend its capabilities and simplify common tasks:\n",
    "\n",
    "- **TorchVision**: Provides datasets, data loaders, and image transformations for computer vision tasks.\n",
    "- **TorchText**: Offers data loading, preprocessing, and tokenization for natural language processing.\n",
    "- **TorchAudio**: Provides tools for loading, preprocessing, and augmenting audio data.\n",
    "- **Fairseq**: A sequence-to-sequence toolkit for tasks like machine translation, summarization, and text generation.\n",
    "- **PyTorch Lightning**: A high-level wrapper that simplifies training, validation, and testing of deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color:black; padding: 10px;\">\n",
    "    We begin to cover the documentation from here onwards\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Dcoumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightyellow; color:black; padding: 10px;\">\n",
    "Features described in this documentation are classified by release status:\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Stable: These features will be maintained long-term and there should generally be no major performance limitations or gaps in documentation. We also expect to maintain backwards compatibility (although breaking changes can happen and notice will be given one release ahead of time).\n",
    "\n",
    "Beta: These features are tagged as Beta because the API may change based on user feedback, because the performance needs to improve, or because coverage across operators is not yet complete. For Beta features, we are committing to seeing the feature through to the Stable classification. We are not, however, committing to backwards compatibility.\n",
    "\n",
    "Prototype: These features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Community\n",
    "- Developer Notes\n",
    "- Language Bindings\n",
    "- Python API\n",
    "- Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making imports before implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch package contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors. Additionally, it provides many utilities for efficient serialization of Tensors and arbitrary types, and other useful utilities.\n",
    "\n",
    "It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightyellow; color:black; padding: 10px;\">\n",
    "Compute capability is a version number assigned by NVIDIA to its GPU architectures, indicating the set of hardware and software features supported by a particular GPU. It helps determine compatibility with CUDA versions and features, impacting performance and efficiency\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_tensor` - Returns True if obj is a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x2 = [1,2,3]\n",
    "x3 = np.array([1,2,3])\n",
    "x4 = torch.tensor([1,2,3])\n",
    "print(torch.is_tensor(x2))\n",
    "print(torch.is_tensor(x3))\n",
    "print(torch.is_tensor(x4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_storage` - Returns True if obj is a PyTorch storage object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_complex` - Returns True if the data type of input is a complex data type i.e., one of torch.complex64, and torch.complex128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_part = torch.tensor([1.0, 2.0, 3.0])\n",
    "imaginary_part = torch.tensor([0.5, 1.5, 2.5])\n",
    "\n",
    "# Combine them into a complex tensor\n",
    "complex_tensor = torch.complex(real_part, imaginary_part)\n",
    "\n",
    "torch.is_complex(complex_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_conj` - Returns True if the input is a conjugated tensor, i.e. its conjugate bit is set to True.\n",
    "\n",
    "\n",
    ">Conjugate Bit: PyTorch uses a “conjugate bit” to efficiently manage conjugation without immediately altering data. This allows for lazy evaluation, where the actual conjugation is materialized only when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_conj(complex_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.+0.5000j, 2.+1.5000j, 3.+2.5000j])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.-0.5000j, 2.-1.5000j, 3.-2.5000j])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(complex_tensor)\n",
    "conj_tensor = torch.conj(complex_tensor)\n",
    "conj_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_conj(conj_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_floating_point` - Returns True if the data type of input is a floating point data type i.e., one of torch.float64, torch.float32, torch.float16, and torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x4 = torch.tensor([1,2,3])\n",
    "print(torch.is_floating_point(x4[0]))\n",
    "print(torch.is_floating_point(torch.tensor([4.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_nonzero` - Returns True if the input is a single element tensor which is not equal to zero after type conversions. i.e. not equal to torch.tensor([0.]) or torch.tensor([0]) or torch.tensor([False]). \n",
    "\n",
    "Throws a RuntimeError if torch.numel() != 1 (even in case of sparse tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.is_nonzero(torch.tensor([0.])))\n",
    "print(torch.is_nonzero(torch.tensor([1.5])))\n",
    "print(torch.is_nonzero(torch.tensor([False])))\n",
    "print(torch.is_nonzero(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with no values is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mis_nonzero(torch\u001b[39m.\u001b[39mtensor([])))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with no values is ambiguous"
     ]
    }
   ],
   "source": [
    "print(torch.is_nonzero(torch.tensor([])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mis_nonzero(torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m])))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "print(torch.is_nonzero(torch.tensor([1, 3, 5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_default_dtype` - Sets the default floating point dtype to d. Supports floating point dtype as inputs. Other dtypes will cause torch to raise an exception.\n",
    "\n",
    "When PyTorch is initialized its default floating point dtype is torch.float32, and the intent of set_default_dtype(torch.float64) is to facilitate NumPy-like type inference. The default floating point dtype is used to:\n",
    "\n",
    "- Implicitly determine the default complex dtype. When the default floating type is float16, the default complex dtype is complex32. For float32, the default complex dtype is complex64. For float64, it is complex128. For bfloat16, an exception will be raised because there is no corresponding complex type for bfloat16.\n",
    "\n",
    "- Infer the dtype for tensors constructed using Python floats or complex Python numbers. See examples below.\n",
    "\n",
    "- Determine the result of type promotion between bool and integer tensors and Python floats and complex Python numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.complex32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial default for floating point is torch.float32\n",
    "# Python floats are interpreted as float32\n",
    "print(torch.tensor([1.2, 3]).dtype)\n",
    "# initial default for floating point is torch.complex64\n",
    "# Complex Python numbers are interpreted as complex64\n",
    "torch.tensor([1.2, 3j]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.complex128\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "# Python floats are now interpreted as float64\n",
    "print(torch.tensor([1.2, 3]).dtype ) # a new floating point tensor\n",
    "# Complex Python numbers are now interpreted as complex128\n",
    "print(torch.tensor([1.2, 3j]).dtype)  # a new complex tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "torch.complex32\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float16)\n",
    "# Python floats are now interpreted as float16\n",
    "print(torch.tensor([1.2, 3]).dtype)  # a new floating point tensor\n",
    "# Complex Python numbers are now interpreted as complex128\n",
    "print(torch.tensor([1.2, 3j]).dtype)  # a new complex tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_default_dtype`-Get the current default floating point torch.dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()  # initial default for floating point is torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float16)\n",
    "torch.get_default_dtype()  # default is now changed to torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_default_device` - Sets the default torch.Tensor to be allocated on device. This does not affect factory function calls which are called with an explicit device argument. Factory calls will be performed as if they were passed device as an argument.\n",
    "\n",
    "To only temporarily change the default device instead of setting it globally, use with torch.device(device): instead.\n",
    "\n",
    "The default device is initially cpu. If you set the default tensor device to another device (e.g., cuda) without a device index, tensors will be allocated on whatever the current device for the device type, even after torch.cuda.set_device() is called.\n",
    "\n",
    "\n",
    "<div style=\"background-color:pink;color:'black'\">\n",
    "This function imposes a slight performance cost on every Python call to the torch API (not just factory functions).\n",
    "<br>\n",
    "<br>\n",
    "This doesn’t affect functions that create tensors that share the same memory as the input, like: torch.from_numpy() and torch.frombuffer()\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#If you don't have 'cuda' this will cause an assertion error when getting the default device. With this error `AssertionError: Torch not compiled with CUDA enabled`\u001b[39;00m\n\u001b[1;32m      2\u001b[0m torch\u001b[39m.\u001b[39mset_default_device(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m torch\u001b[39m.\u001b[39mget_default_device()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/__init__.py:1047\u001b[0m, in \u001b[0;36mget_default_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[39mreturn\u001b[39;00m device\n\u001b[1;32m   1044\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m         \u001b[39m# TODO: Call like get_device_index() method corresponding to\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m         \u001b[39m# each device type\u001b[39;00m\n\u001b[0;32m-> 1047\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor([])\u001b[39m.\u001b[39mdevice\n\u001b[1;32m   1048\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_device.py:106\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m _device_constructors() \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m\"\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#If you don't have 'cuda' this will cause an assertion error when getting the default device. With this error `AssertionError: Torch not compiled with CUDA enabled`\n",
    "torch.set_default_device('cuda') # the default index is 0 \n",
    "torch.get_default_device()\n",
    "# torch.set_default_device('cuda:1') #setting cuda device with an index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_device('cpu')\n",
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_default_tensor_type` - Sets the default torch.Tensor type to floating point tensor type t. This type will also be used as default floating point type for type inference in torch.tensor().\n",
    "\n",
    "The default floating point tensor type is initially torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1.2, 3]).dtype )   # initial default for floating point is torch.float32\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(torch.tensor([1.2, 3]).dtype)    # a new floating point tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor) # Resetting it back to normal (THIS IS NOT NECESSARY TO IMPLEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numel`-Returns the total number of elements in the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 2, 3, 4, 5)\n",
    "torch.numel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.7011,  1.0103,  0.1894, -0.1033,  0.4773],\n",
       "           [ 0.6510, -0.9430, -0.7517, -0.9230, -0.5099],\n",
       "           [-0.6429, -0.7627, -1.2835, -0.0746, -0.1894],\n",
       "           [ 0.6214, -0.9040,  1.6536,  0.1792,  1.5377]],\n",
       "\n",
       "          [[ 0.0561, -0.0865, -0.3846, -0.7385,  0.8295],\n",
       "           [ 1.2002, -0.0816, -0.6125,  0.0634, -0.3631],\n",
       "           [ 0.6632, -0.8936,  2.1819, -1.0627, -0.9134],\n",
       "           [-1.7668, -0.2770, -0.3437,  0.4954,  1.6466]],\n",
       "\n",
       "          [[-0.4742,  0.1322, -0.2055, -0.3401,  0.1761],\n",
       "           [ 0.6556, -1.8690, -0.3728,  1.5104, -0.2071],\n",
       "           [ 0.9153,  0.5175, -0.1224, -0.3738, -1.2143],\n",
       "           [-0.4021,  0.6956,  1.1614, -0.2235, -0.4531]]],\n",
       "\n",
       "\n",
       "         [[[-1.6839, -0.5010, -0.3725,  0.2648,  1.0725],\n",
       "           [-1.1364,  1.4070,  0.9047,  1.3125, -0.0574],\n",
       "           [ 0.6914, -0.4821,  0.4485, -0.0542, -0.3414],\n",
       "           [-0.0939,  0.2098, -0.2662,  1.2091, -0.0903]],\n",
       "\n",
       "          [[-0.2650, -1.3057,  0.3733,  0.1206,  0.2209],\n",
       "           [-1.3337, -0.4397,  0.0961,  0.0517,  0.8893],\n",
       "           [ 0.6457,  0.6225,  0.5282,  0.7110,  1.8470],\n",
       "           [ 0.5805,  0.6269,  0.1901, -0.1200, -0.5630]],\n",
       "\n",
       "          [[-0.1711,  0.4751,  0.9971,  0.1629,  0.1513],\n",
       "           [ 1.6068,  0.3274, -0.1369,  1.0075,  1.6202],\n",
       "           [-0.2073,  0.4235,  0.8145,  0.0998, -1.3071],\n",
       "           [ 1.8331,  0.3007, -0.3942,  0.4537, -0.4228]]]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(4,4)\n",
    "torch.numel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_printoptions`-Set options for printing. Items shamelessly taken from NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.12])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the precision of elements\n",
    "torch.set_printoptions(precision=2)\n",
    "torch.tensor([1.12345])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2,  ..., 7, 8, 9])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the number of elements shown\n",
    "torch.set_printoptions(threshold=5)\n",
    "torch.arange(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1235])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore defaults\n",
    "torch.set_printoptions(profile='default')\n",
    "torch.tensor([1.12345])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_flush_denormal` - Disables denormal floating numbers on CPU.\n",
    "\n",
    "Returns True if your system supports flushing denormal numbers and it successfully configures flush denormal mode. set_flush_denormal() is supported on x86 architectures supporting SSE3 and AArch64 architecture.\n",
    "<div style=\"background-color:lightyellow;color:'black'\">\n",
    "Denormal numbers, also known as subnormal numbers, are a special category of floating-point numbers used to represent values very close to zero that are smaller than the smallest normal floating-point number.\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1e-323], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.8813e-324], dtype=torch.float64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1e-323], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(True) # Resetting it back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.tensor` - Constructs a tensor with no autograd history (also known as a “leaf tensor”, see Autograd mechanics) by copying data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
