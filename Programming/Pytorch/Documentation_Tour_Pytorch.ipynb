{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation Tour - Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Release Blog](https://pytorch.org/blog/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a popular open-source machine learning library built on top of the Torch library. It's particularly well-suited for deep learning applications due to its dynamic computational graph, which allows for more flexible and intuitive development.\n",
    "\n",
    "## Key Features and Benefits:\n",
    "\n",
    "- `Dynamic Computational Graph`: Unlike static frameworks, PyTorch allows you to define and modify the computational graph on the fly, making it easier to experiment and debug.\n",
    "- `Tensor Operations`: PyTorch provides efficient tensor operations for numerical computations, essential for deep learning models.\n",
    "- `Autograd`: Automatically calculates gradients for backpropagation, simplifying the training process.\n",
    "- `CUDA Integration`: Supports GPU acceleration for faster training and inference, especially on large datasets.\n",
    "- `Community and Ecosystem`: A large and active community contributes to PyTorch's development and provides a wealth of resources, including tutorials, libraries, and tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Family of Libraries\n",
    "\n",
    "PyTorch has a growing ecosystem of libraries that extend its capabilities and simplify common tasks:\n",
    "\n",
    "- **TorchVision**: Provides datasets, data loaders, and image transformations for computer vision tasks.\n",
    "- **TorchText**: Offers data loading, preprocessing, and tokenization for natural language processing.\n",
    "- **TorchAudio**: Provides tools for loading, preprocessing, and augmenting audio data.\n",
    "- **Fairseq**: A sequence-to-sequence toolkit for tasks like machine translation, summarization, and text generation.\n",
    "- **PyTorch Lightning**: A high-level wrapper that simplifies training, validation, and testing of deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color:black; padding: 10px;\">\n",
    "    We begin to cover the documentation from here onwards\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Dcoumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightyellow; color:black; padding: 10px;\">\n",
    "Features described in this documentation are classified by release status:\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Stable: These features will be maintained long-term and there should generally be no major performance limitations or gaps in documentation. We also expect to maintain backwards compatibility (although breaking changes can happen and notice will be given one release ahead of time).\n",
    "\n",
    "Beta: These features are tagged as Beta because the API may change based on user feedback, because the performance needs to improve, or because coverage across operators is not yet complete. For Beta features, we are committing to seeing the feature through to the Stable classification. We are not, however, committing to backwards compatibility.\n",
    "\n",
    "Prototype: These features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Community\n",
    "- Developer Notes\n",
    "- Language Bindings\n",
    "- Python API\n",
    "- Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Design Philosophy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principle 1:  Usability over Performance**\n",
    "\n",
    "Pytorch's primary goal is Usability. It'secondary goal is to provide this usability with a reasonable performance.\n",
    "\n",
    "In more concrete terms, it is operated in a usability-first manner and try to avoid jumping to restriction-first regimes (for example, static shapes, graph-mode only) without a clear-eyed view of the tradeoffs. (snide on tensorflow lol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Principle 2: Simple Over Easy**\n",
    "\n",
    "- Explicit is better than implicit\n",
    "\n",
    "Simple / Explicit (to understand, debug): every tensor is associated with a device. The user explicitly specifies tensor device movement. Operations that require cross-device movement result in an error.\n",
    "\n",
    "- Simple is better than complex\n",
    "\n",
    "Easy / Implicit (to use): the user does not have to worry about devices; the system figures out the globally optimal device placement.\n",
    "\n",
    "Some classic arguments in favor of this sort of design come from A Note on Distributed Computation (TLDR: Do not model resources with very different performance characteristics uniformly, the details will leak) and the End-to-End Principle (TLDR: building smarts into the lower-layers of the stack can prevent building performant features at higher layers in the stack, and often doesn’t work anyway). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principle 3: Python First with Best In Class Language Interoperability**\n",
    "\n",
    "PyTorch is not a Python binding into a monolithic C++ framework. It is built to be deeply integrated into Python. You can use it naturally like you would use NumPy, SciPy, scikit-learn, or other Python libraries. You can write your new neural network layers in Python itself, using your favorite libraries and use packages such as Cython and Numba. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developer Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content on this will be presented in the `Deep Dive on Pytorch` notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Bindings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Javadoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making imports before implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_module_version(module:str):\n",
    "    try:\n",
    "        version = importlib.metadata.version(module)\n",
    "        print(f\"{module} version: \",version)\n",
    "    except:\n",
    "        print(f\"We could not find a version for {module} or the module is not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.0.0\n",
      "torchaudio version:  2.0.0\n",
      "torchvision version:  0.15.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print_module_version(\"torch\")\n",
    "import torchaudio\n",
    "print_module_version(\"torchaudio\")\n",
    "import torchvision\n",
    "print_module_version(\"torchvision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch package contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors. Additionally, it provides many utilities for efficient serialization of Tensors and arbitrary types, and other useful utilities.\n",
    "\n",
    "It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightyellow; color:black; padding: 10px;\">\n",
    "Compute capability is a version number assigned by NVIDIA to its GPU architectures, indicating the set of hardware and software features supported by a particular GPU. It helps determine compatibility with CUDA versions and features, impacting performance and efficiency\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_tensor` - Returns True if obj is a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x2 = [1,2,3]\n",
    "x3 = np.array([1,2,3])\n",
    "x4 = torch.tensor([1,2,3])\n",
    "print(torch.is_tensor(x2))\n",
    "print(torch.is_tensor(x3))\n",
    "print(torch.is_tensor(x4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_storage` - Returns True if obj is a PyTorch storage object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_complex` - Returns True if the data type of input is a complex data type i.e., one of torch.complex64, and torch.complex128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_part = torch.tensor([1.0, 2.0, 3.0])\n",
    "imaginary_part = torch.tensor([0.5, 1.5, 2.5])\n",
    "\n",
    "# Combine them into a complex tensor\n",
    "complex_tensor = torch.complex(real_part, imaginary_part)\n",
    "\n",
    "torch.is_complex(complex_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_conj` - Returns True if the input is a conjugated tensor, i.e. its conjugate bit is set to True.\n",
    "\n",
    "\n",
    ">Conjugate Bit: PyTorch uses a “conjugate bit” to efficiently manage conjugation without immediately altering data. This allows for lazy evaluation, where the actual conjugation is materialized only when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_conj(complex_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.+0.5000j, 2.+1.5000j, 3.+2.5000j])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.-0.5000j, 2.-1.5000j, 3.-2.5000j])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(complex_tensor)\n",
    "conj_tensor = torch.conj(complex_tensor)\n",
    "conj_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_conj(conj_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_floating_point` - Returns True if the data type of input is a floating point data type i.e., one of torch.float64, torch.float32, torch.float16, and torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x4 = torch.tensor([1,2,3])\n",
    "print(torch.is_floating_point(x4[0]))\n",
    "print(torch.is_floating_point(torch.tensor([4.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_nonzero` - Returns True if the input is a single element tensor which is not equal to zero after type conversions. i.e. not equal to torch.tensor([0.]) or torch.tensor([0]) or torch.tensor([False]). \n",
    "\n",
    "Throws a RuntimeError if torch.numel() != 1 (even in case of sparse tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.is_nonzero(torch.tensor([0.])))\n",
    "print(torch.is_nonzero(torch.tensor([1.5])))\n",
    "print(torch.is_nonzero(torch.tensor([False])))\n",
    "print(torch.is_nonzero(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with no values is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mis_nonzero(torch\u001b[39m.\u001b[39mtensor([])))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with no values is ambiguous"
     ]
    }
   ],
   "source": [
    "print(torch.is_nonzero(torch.tensor([])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mis_nonzero(torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m])))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "print(torch.is_nonzero(torch.tensor([1, 3, 5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_default_dtype` - Sets the default floating point dtype to d. Supports floating point dtype as inputs. Other dtypes will cause torch to raise an exception.\n",
    "\n",
    "When PyTorch is initialized its default floating point dtype is torch.float32, and the intent of set_default_dtype(torch.float64) is to facilitate NumPy-like type inference. The default floating point dtype is used to:\n",
    "\n",
    "- Implicitly determine the default complex dtype. When the default floating type is float16, the default complex dtype is complex32. For float32, the default complex dtype is complex64. For float64, it is complex128. For bfloat16, an exception will be raised because there is no corresponding complex type for bfloat16.\n",
    "\n",
    "- Infer the dtype for tensors constructed using Python floats or complex Python numbers. See examples below.\n",
    "\n",
    "- Determine the result of type promotion between bool and integer tensors and Python floats and complex Python numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.complex32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial default for floating point is torch.float32\n",
    "# Python floats are interpreted as float32\n",
    "print(torch.tensor([1.2, 3]).dtype)\n",
    "# initial default for floating point is torch.complex64\n",
    "# Complex Python numbers are interpreted as complex64\n",
    "torch.tensor([1.2, 3j]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.complex128\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "# Python floats are now interpreted as float64\n",
    "print(torch.tensor([1.2, 3]).dtype ) # a new floating point tensor\n",
    "# Complex Python numbers are now interpreted as complex128\n",
    "print(torch.tensor([1.2, 3j]).dtype)  # a new complex tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "torch.complex32\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float16)\n",
    "# Python floats are now interpreted as float16\n",
    "print(torch.tensor([1.2, 3]).dtype)  # a new floating point tensor\n",
    "# Complex Python numbers are now interpreted as complex128\n",
    "print(torch.tensor([1.2, 3j]).dtype)  # a new complex tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_default_dtype`-Get the current default floating point torch.dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()  # initial default for floating point is torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float16)\n",
    "torch.get_default_dtype()  # default is now changed to torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_default_device` - Sets the default torch.Tensor to be allocated on device. This does not affect factory function calls which are called with an explicit device argument. Factory calls will be performed as if they were passed device as an argument.\n",
    "\n",
    "To only temporarily change the default device instead of setting it globally, use with torch.device(device): instead.\n",
    "\n",
    "The default device is initially cpu. If you set the default tensor device to another device (e.g., cuda) without a device index, tensors will be allocated on whatever the current device for the device type, even after torch.cuda.set_device() is called.\n",
    "\n",
    "\n",
    "<div style=\"background-color:pink;color:'black'\">\n",
    "This function imposes a slight performance cost on every Python call to the torch API (not just factory functions).\n",
    "<br>\n",
    "<br>\n",
    "This doesn’t affect functions that create tensors that share the same memory as the input, like: torch.from_numpy() and torch.frombuffer()\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#If you don't have 'cuda' this will cause an assertion error when getting the default device. With this error `AssertionError: Torch not compiled with CUDA enabled`\u001b[39;00m\n\u001b[1;32m      2\u001b[0m torch\u001b[39m.\u001b[39mset_default_device(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m torch\u001b[39m.\u001b[39mget_default_device()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/__init__.py:1047\u001b[0m, in \u001b[0;36mget_default_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[39mreturn\u001b[39;00m device\n\u001b[1;32m   1044\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m         \u001b[39m# TODO: Call like get_device_index() method corresponding to\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m         \u001b[39m# each device type\u001b[39;00m\n\u001b[0;32m-> 1047\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor([])\u001b[39m.\u001b[39mdevice\n\u001b[1;32m   1048\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_device.py:106\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m _device_constructors() \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m\"\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#If you don't have 'cuda' this will cause an assertion error when getting the default device. With this error `AssertionError: Torch not compiled with CUDA enabled`\n",
    "torch.set_default_device('cuda') # the default index is 0 \n",
    "torch.get_default_device()\n",
    "# torch.set_default_device('cuda:1') #setting cuda device with an index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_device('cpu')\n",
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_default_tensor_type` - Sets the default torch.Tensor type to floating point tensor type t. This type will also be used as default floating point type for type inference in torch.tensor().\n",
    "\n",
    "The default floating point tensor type is initially torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1.2, 3]).dtype )   # initial default for floating point is torch.float32\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(torch.tensor([1.2, 3]).dtype)    # a new floating point tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor) # Resetting it back to normal (THIS IS NOT NECESSARY TO IMPLEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numel`-Returns the total number of elements in the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 2, 3, 4, 5)\n",
    "torch.numel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.7011,  1.0103,  0.1894, -0.1033,  0.4773],\n",
       "           [ 0.6510, -0.9430, -0.7517, -0.9230, -0.5099],\n",
       "           [-0.6429, -0.7627, -1.2835, -0.0746, -0.1894],\n",
       "           [ 0.6214, -0.9040,  1.6536,  0.1792,  1.5377]],\n",
       "\n",
       "          [[ 0.0561, -0.0865, -0.3846, -0.7385,  0.8295],\n",
       "           [ 1.2002, -0.0816, -0.6125,  0.0634, -0.3631],\n",
       "           [ 0.6632, -0.8936,  2.1819, -1.0627, -0.9134],\n",
       "           [-1.7668, -0.2770, -0.3437,  0.4954,  1.6466]],\n",
       "\n",
       "          [[-0.4742,  0.1322, -0.2055, -0.3401,  0.1761],\n",
       "           [ 0.6556, -1.8690, -0.3728,  1.5104, -0.2071],\n",
       "           [ 0.9153,  0.5175, -0.1224, -0.3738, -1.2143],\n",
       "           [-0.4021,  0.6956,  1.1614, -0.2235, -0.4531]]],\n",
       "\n",
       "\n",
       "         [[[-1.6839, -0.5010, -0.3725,  0.2648,  1.0725],\n",
       "           [-1.1364,  1.4070,  0.9047,  1.3125, -0.0574],\n",
       "           [ 0.6914, -0.4821,  0.4485, -0.0542, -0.3414],\n",
       "           [-0.0939,  0.2098, -0.2662,  1.2091, -0.0903]],\n",
       "\n",
       "          [[-0.2650, -1.3057,  0.3733,  0.1206,  0.2209],\n",
       "           [-1.3337, -0.4397,  0.0961,  0.0517,  0.8893],\n",
       "           [ 0.6457,  0.6225,  0.5282,  0.7110,  1.8470],\n",
       "           [ 0.5805,  0.6269,  0.1901, -0.1200, -0.5630]],\n",
       "\n",
       "          [[-0.1711,  0.4751,  0.9971,  0.1629,  0.1513],\n",
       "           [ 1.6068,  0.3274, -0.1369,  1.0075,  1.6202],\n",
       "           [-0.2073,  0.4235,  0.8145,  0.0998, -1.3071],\n",
       "           [ 1.8331,  0.3007, -0.3942,  0.4537, -0.4228]]]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(4,4)\n",
    "torch.numel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_printoptions`-Set options for printing. Items shamelessly taken from NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.12])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the precision of elements\n",
    "torch.set_printoptions(precision=2)\n",
    "torch.tensor([1.12345])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2,  ..., 7, 8, 9])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the number of elements shown\n",
    "torch.set_printoptions(threshold=5)\n",
    "torch.arange(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1235])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore defaults\n",
    "torch.set_printoptions(profile='default')\n",
    "torch.tensor([1.12345])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_flush_denormal` - Disables denormal floating numbers on CPU.\n",
    "\n",
    "Returns True if your system supports flushing denormal numbers and it successfully configures flush denormal mode. set_flush_denormal() is supported on x86 architectures supporting SSE3 and AArch64 architecture.\n",
    "<div style=\"background-color:lightyellow;color:'black'\">\n",
    "Denormal numbers, also known as subnormal numbers, are a special category of floating-point numbers used to represent values very close to zero that are smaller than the smallest normal floating-point number.\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1e-323], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.8813e-324], dtype=torch.float64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1e-323], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(True) # Resetting it back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Creation Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.tensor` - Constructs a tensor with no autograd history (also known as a “leaf tensor”, see Autograd mechanics) by copying data.\n",
    "\n",
    "**Parameters**\n",
    "data (array_like) – Initial data for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types.\n",
    "\n",
    "**Keyword Arguments**\n",
    "dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, infers data type from data.\n",
    "device (torch.device, optional) – the device of the constructed tensor. If None and data is a tensor then the device of data is used. If None and data is not a tensor then the result tensor is constructed on the current device.\n",
    "requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "pin_memory (bool, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 1.2000],\n",
       "        [2.2000, 3.1000],\n",
       "        [4.9000, 5.2000]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0, 1])  # Type inference on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1111, 0.2222, 0.3333]], dtype=torch.float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
    "             dtype=torch.float64,\n",
    "             device=torch.device('cpu'))  # creates a double tensor on a CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1416)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(3.14159)  # Create a zero-dimensional (scalar) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([])  # Create an empty tensor (of size (0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sparse_coo_tensor`- Constructs a sparse tensor in COO(rdinate) format with specified values at the given indices.\n",
    "\n",
    "<div style=\"background-color:lightyellow;color:black\">\n",
    "A sparse tensor is a multi-dimensional array where most elements are zero, allowing for efficient storage and computation by focusing on non-zero elements. It is represented using three components: indices, which specify the locations of non-zero elements; values, which are the non-zero entries themselves; and shape, which defines the dimensions of the tensor. \n",
    "<br>\n",
    "<br>\n",
    "The COO (Coordinate) format is a method for storing sparse matrices and tensors by explicitly listing their non-zero elements and their positions. It uses three arrays:\n",
    "\t1.\tRow Indices: An array indicating the row positions of non-zero elements.\n",
    "\t2.\tColumn Indices: An array indicating the column positions of non-zero elements.\n",
    "\t3.\tData: An array containing the non-zero values themselves.\n",
    "This format is also known as the ‘ijv’ or ‘triplet’ format and is particularly useful for constructing sparse matrices due to its simplicity and ease of conversion to other formats.\n",
    "</div>\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- indices (array_like) – Initial data for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types. Will be cast to a torch.LongTensor internally. The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.\n",
    "values (array_like) – Initial values for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types.\n",
    "- size (list, tuple, or torch.Size, optional) – Size of the sparse tensor. If not provided the size will be inferred as the minimum size big enough to hold all non-zero elements.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, infers data type from values.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_device()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "pin_memory (bool, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False.\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "- check_invariants (bool, optional) – If sparse tensor invariants are checked. Default: as returned by torch.sparse.check_sparse_tensor_invariants.is_enabled(), initially False.\n",
    "- is_coalesced (bool, optional) – When``True``, the caller is responsible for providing tensor indices that correspond to a coalesced tensor. If the check_invariants flag is False, no error will be raised if the prerequisites are not met and this will lead to silently incorrect results. To force coalescion please use coalesce() on the resulting Tensor. Default: None: except for trivial cases (e.g. nnz < 2) the resulting Tensor has is_coalesced set to False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 1, 1],\n",
       "                       [2, 0, 2]]),\n",
       "       values=tensor([3., 4., 5.]),\n",
       "       size=(2, 4), nnz=3, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1],\n",
    "                  [2, 0, 2]])\n",
    "v = torch.tensor([3, 4, 5], dtype=torch.float32)\n",
    "torch.sparse_coo_tensor(i, v, [2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 1, 1],\n",
       "                       [2, 0, 2]]),\n",
       "       values=tensor([3., 4., 5.]),\n",
       "       size=(2, 3), nnz=3, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.sparse_coo_tensor(i, v)  # Shape inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 1, 1],\n",
       "                       [2, 0, 2]]),\n",
       "       values=tensor([3., 4., 5.]),\n",
       "       size=(2, 4), nnz=3, dtype=torch.float64, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.sparse_coo_tensor(i, v, [2, 4],\n",
    "                        dtype=torch.float64,\n",
    "                        device=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([], size=(1, 0)),\n",
       "       values=tensor([], size=(0,)),\n",
       "       size=(1,), nnz=0, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "S = torch.sparse_coo_tensor(torch.empty([1, 0]), [], [1])\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([], size=(1, 0)),\n",
       "       values=tensor([], size=(0, 2)),\n",
       "       size=(1, 2), nnz=0, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "S = torch.sparse_coo_tensor(torch.empty([1, 0]), torch.empty([0, 2]), [1, 2])\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.sparse.FloatTensor'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sparse_csr_tensor`- Constructs a sparse tensor in CSR (Compressed Sparse Row) with specified values at the given crow_indices and col_indices. Sparse matrix multiplication operations in CSR format are typically faster than that for sparse tensors in COO format. Make you have a look at the note on the data type of the indices.\n",
    "\n",
    "The Compressed Sparse Row (CSR) format is a method for efficiently storing sparse matrices. It uses three one-dimensional arrays:\n",
    "\n",
    "1. **Data Array**: Contains all the non-zero values of the matrix in row-major order.\n",
    "2. **Indices Array**: Stores the column indices corresponding to each non-zero value in the data array.\n",
    "3. **Indptr Array**: Holds the cumulative count of non-zero elements per row, marking where each row starts and ends in the data and indices arrays. Its length is $$n_{\\text{rows}} + 1$$, with the last element being the total number of non-zero elements[2][3][7].\n",
    "\n",
    "CSR format is advantageous for fast arithmetic operations and efficient matrix-vector multiplications.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- crow_indices (array_like) – (B+1)-dimensional array of size (*batchsize, nrows + 1). The last element of each batch is the number of non-zeros. This tensor encodes the index in values and col_indices depending on where the given row starts. Each successive number in the tensor subtracted by the number before it denotes the number of elements in a given row.\n",
    "- col_indices (array_like) – Column co-ordinates of each element in values. (B+1)-dimensional tensor with the same length as values.\n",
    "values (array_list) – Initial values for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types that represents a (1+K)-dimensional tensor where K is the number of dense dimensions.\n",
    "- size (list, tuple, torch.Size, optional) – Size of the sparse tensor: (*batchsize, nrows, ncols, *densesize). If not provided, the size will be inferred as the minimum size big enough to hold all non-zero elements.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, infers data type from values.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_device()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "- pin_memory (bool, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False.\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "- check_invariants (bool, optional) – If sparse tensor invariants are checked. Default: as returned by torch.sparse.check_sparse_tensor_invariants.is_enabled(), initially False.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse CSR Tensor:\n",
      " tensor(crow_indices=tensor([0, 1, 2]),\n",
      "       col_indices=tensor([2, 0]),\n",
      "       values=tensor([3, 4]), size=(2, 3), nnz=2, layout=torch.sparse_csr)\n"
     ]
    }
   ],
   "source": [
    "# Constructs a sparse tensor in CSR format.\n",
    "crow_indices = torch.tensor([0, 1, 2])\n",
    "col_indices = torch.tensor([2, 0])\n",
    "values_csr = torch.tensor([3, 4])\n",
    "sparse_csr = torch.sparse_csr_tensor(crow_indices, col_indices, values_csr)\n",
    "print(\"Sparse CSR Tensor:\\n\", sparse_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sparse_csc_tensor`- Constructs a sparse tensor in CSC (Compressed Sparse Column) with specified values at the given ccol_indices and row_indices. Sparse matrix multiplication operations in CSC format are typically faster than that for sparse tensors in COO format. Make you have a look at the note on the data type of the indices.\n",
    "\n",
    "<div style=\"background-color:lightyellow;color:black\">\n",
    "If the device argument is not specified the device of the given values and indices tensor(s) must match. If, however, the argument is specified the input Tensors will be converted to the given device and in turn determine the device of the constructed sparse tensor.\n",
    "</div>\n",
    "\n",
    "**Parameters**\n",
    "- ccol_indices (array_like) – (B+1)-dimensional array of size (*batchsize, ncols + 1). The last element of each batch is the number of non-zeros. This tensor encodes the index in values and row_indices depending on where the given column starts. Each successive number in the tensor subtracted by the number before it denotes the number of elements in a given column.\n",
    "- row_indices (array_like) – Row co-ordinates of each element in values. (B+1)-dimensional tensor with the same length as values.\n",
    "values (array_list) – Initial values for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types that represents a (1+K)-dimensional tensor where K is the number of dense dimensions.\n",
    "- size (list, tuple, torch.Size, optional) – Size of the sparse tensor: (*batchsize, nrows, ncols, *densesize). If not provided, the size will be inferred as the minimum size big enough to hold all non-zero elements.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, infers data type from values.\n",
    "device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_device()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "- pin_memory (bool, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False.\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "- check_invariants (bool, optional) – If sparse tensor invariants are checked. Default: as returned by torch.sparse.check_sparse_tensor_invariants.is_enabled(), initially False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(ccol_indices=tensor([0, 2, 4]),\n",
       "       row_indices=tensor([0, 1, 0, 1]),\n",
       "       values=tensor([1., 2., 3., 4.]), size=(2, 2), nnz=4,\n",
       "       dtype=torch.float64, layout=torch.sparse_csc)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccol_indices = [0, 2, 4]\n",
    "row_indices = [0, 1, 0, 1]\n",
    "values = [1, 2, 3, 4]\n",
    "torch.sparse_csc_tensor(torch.tensor(ccol_indices, dtype=torch.int64),\n",
    "                        torch.tensor(row_indices, dtype=torch.int64),\n",
    "                        torch.tensor(values), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sparse_bsr_tensor` - Constructs a sparse tensor in BSR (Block Compressed Sparse Row)) with specified 2-dimensional blocks at the given crow_indices and col_indices. Sparse matrix multiplication operations in BSR format are typically faster than that for sparse tensors in COO format. Make you have a look at the note on the data type of the indices.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- crow_indices (array_like) – (B+1)-dimensional array of size (*batchsize, nrowblocks + 1). The last element of each batch is the number of non-zeros. This tensor encodes the block index in values and col_indices depending on where the given row block starts. Each successive number in the tensor subtracted by the number before it denotes the number of blocks in a given row.\n",
    "- col_indices (array_like) – Column block co-ordinates of each block in values. (B+1)-dimensional tensor with the same length as values.\n",
    "values (array_list) – Initial values for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types that represents a (1 + 2 + K)-dimensional tensor where K is the number of dense dimensions.\n",
    "- size (list, tuple, torch.Size, optional) – Size of the sparse tensor: (*batchsize, nrows * blocksize[0], ncols * blocksize[1], *densesize) where blocksize == values.shape[1:3]. If not provided, the size will be inferred as the minimum size big enough to hold all non-zero blocks.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, infers data type from values.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_device()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "- pin_memory (bool, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False.\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "- check_invariants (bool, optional) – If sparse tensor invariants are checked. Default: as returned by torch.sparse.check_sparse_tensor_invariants.is_enabled(), initially False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(crow_indices=tensor([0, 1, 2]),\n",
       "       col_indices=tensor([0, 1]),\n",
       "       values=tensor([[[1., 2.],\n",
       "                       [3., 4.]],\n",
       "\n",
       "                      [[5., 6.],\n",
       "                       [7., 8.]]]), size=(4, 4), nnz=2, dtype=torch.float64,\n",
       "       layout=torch.sparse_bsr)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crow_indices = [0, 1, 2]\n",
    "col_indices = [0, 1]\n",
    "values = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
    "torch.sparse_bsr_tensor(torch.tensor(crow_indices, dtype=torch.int64),\n",
    "                        torch.tensor(col_indices, dtype=torch.int64),\n",
    "                        torch.tensor(values), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sparse_bsc_tensor` - Constructs a sparse tensor in BSC (Block Compressed Sparse Column)) with specified 2-dimensional blocks at the given ccol_indices and row_indices. Sparse matrix multiplication operations in BSC format are typically faster than that for sparse tensors in COO format. Make you have a look at the note on the data type of the indices.\n",
    "\n",
    "**Parameters**\n",
    "- ccol_indices (array_like) – (B+1)-dimensional array of size (*batchsize, ncolblocks + 1). The last element of each batch is the number of non-zeros. This tensor encodes the index in values and row_indices depending on where the given column starts. Each successive number in the tensor subtracted by the number before it denotes the number of elements in a given column.\n",
    "- row_indices (array_like) – Row block co-ordinates of each block in values. (B+1)-dimensional tensor with the same length as values.\n",
    "- values (array_list) – Initial blocks for the tensor. Can be a list, tuple, NumPy ndarray, and other types that represents a (1 + 2 + K)-dimensional tensor where K is the number of dense dimensions.\n",
    "- size (list, tuple, torch.Size, optional) – Size of the sparse tensor: (*batchsize, nrows * blocksize[0], ncols * blocksize[1], *densesize) If not provided, the size will be inferred as the minimum size big enough to hold all non-zero blocks.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, infers data type from values.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_device()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "- pin_memory (bool, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False.\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "- check_invariants (bool, optional) – If sparse tensor invariants are checked. Default: as returned by torch.sparse.check_sparse_tensor_invariants.is_enabled(), initially False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(ccol_indices=tensor([0, 1, 2]),\n",
       "       row_indices=tensor([0, 1]),\n",
       "       values=tensor([[[1., 2.],\n",
       "                       [3., 4.]],\n",
       "\n",
       "                      [[5., 6.],\n",
       "                       [7., 8.]]]), size=(4, 4), nnz=2, dtype=torch.float64,\n",
       "       layout=torch.sparse_bsc)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccol_indices = [0, 1, 2]\n",
    "row_indices = [0, 1]\n",
    "values = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
    "torch.sparse_bsc_tensor(torch.tensor(ccol_indices, dtype=torch.int64),\n",
    "                        torch.tensor(row_indices, dtype=torch.int64),\n",
    "                        torch.tensor(values), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`asarray` - Converts obj to a tensor.\n",
    "\n",
    "obj can be one of:\n",
    "\n",
    "- a tensor\n",
    "- a NumPy array or a NumPy scalar\n",
    "- a DLPack capsule\n",
    "- an object that implements Python’s buffer protocol\n",
    "- a scalar\n",
    "- a sequence of scalars\n",
    "\n",
    "<div style=\"background-color:lightyellow;color:black\">\n",
    "torch.tensor() creates a tensor that always copies the data from the input object. torch.from_numpy() creates a tensor that always shares memory from NumPy arrays. torch.frombuffer() creates a tensor that always shares memory from objects that implement the buffer protocol. torch.from_dlpack() creates a tensor that always shares memory from DLPack capsules.\n",
    "</div>\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- obj (object) – a tensor, NumPy array, DLPack Capsule, object that implements Python’s buffer protocol, scalar, or sequence of scalars.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the datatype of the returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from obj.\n",
    "copy (bool, optional) – controls whether the returned tensor shares memory with obj. Default: None, which causes the returned tensor to share memory with obj whenever possible. If True then the returned tensor does not share its memory. If False then the returned tensor shares its memory with obj and an error is thrown if it cannot.\n",
    "- device (torch.device, optional) – the device of the returned tensor. Default: None, which causes the device of obj to be used. Or, if obj is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient. If True, then the returned tensor will require a gradient, and if obj is also a tensor with an autograd history then the returned tensor will have the same history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "# Shares memory with tensor 'a'\n",
    "b = torch.asarray(a)\n",
    "a.data_ptr() == b.data_ptr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forces memory copy\n",
    "c = torch.asarray(a, copy=True)\n",
    "a.data_ptr() == c.data_ptr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "b = a + 2\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shares memory with tensor 'b', with no grad\n",
    "c = torch.asarray(b)\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shares memory with tensor 'b', retaining autograd history\n",
    "d = torch.asarray(b, requires_grad=True)\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "array = np.array([1, 2, 3])\n",
    "# Shares memory with array 'array'\n",
    "t1 = torch.asarray(array)\n",
    "array.__array_interface__['data'][0] == t1.data_ptr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Copies memory due to dtype mismatch\n",
    "t2 = torch.asarray(array, dtype=torch.float32)\n",
    "array.__array_interface__['data'][0] == t2.data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000, dtype=torch.float64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scalar = np.float64(0.5)\n",
    "torch.asarray(scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`as_tensor` - Converts data into a tensor, sharing data and preserving autograd history if possible.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- obj (object) – a tensor, NumPy array, DLPack Capsule, object that implements Python’s buffer protocol, scalar, or sequence of scalars.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the datatype of the returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from obj.\n",
    "- device (torch.device, optional) – the device of the returned tensor. Default: None, which causes the device of obj to be used. Or, if obj is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient. If True, then the returned tensor will require a gradient, and if obj is also a tensor with an autograd history then the returned tensor will have the same history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "tensor_from_array = torch.as_tensor(array)\n",
    "print(tensor_from_array.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/// Need to understand this better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`as_strided` - Creates a view of an existing torch.Tensor with specified size, stride, and storage_offset.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- input (torch.Tensor) – the input tensor.\n",
    "- size (tuple) – the new size of the tensor.\n",
    "- stride (tuple) – the new stride of the tensor.\n",
    "- storage_offset (int, optional) – the offset in the storage. Default: 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = torch.tensor([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 5],\n",
       "        [2, 4, 6],\n",
       "        [3, 5, 7],\n",
       "        [4, 6, 8]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.as_strided(x, size=(4,3), stride=(1,2))\n",
    "t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from_file` - Creates a CPU tensor with storage backed by a memory-mapped file.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- filename (str) – the name of the file to map into memory.\n",
    "- size (int, optional) – the size of the tensor to be created. If not provided, the size will be inferred from the file.\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from the file.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: None, which causes the device of the returned tensor to be inferred from the file.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0050,  0.2827,  0.3792,  1.2395, -2.7689],\n",
       "        [ 1.6283,  1.7129,  0.2101,  0.8047, -0.9882]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn((2,5), dtype=torch.float64)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10, dtype=torch.float32)\n",
    "x.numpy().tofile(\"tensor_data.bin\")  # Write in binary format\n",
    "\n",
    "# Read back the data\n",
    "y = torch.from_file(\"tensor_data.bin\", size=(10), dtype=torch.float32)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from_numpy` - Creates a Tensor from a numpy.ndarray.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- obj (numpy.ndarray) – the input numpy array.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from obj.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: None, which causes the device of obj to be used. Or, if obj is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "t = torch.from_numpy(x)\n",
    "t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from_dlpack` - Converts a tensor from an external library into a torch.Tensor.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- obj (object) – a tensor, NumPy array, DLPack Capsule, object that implements Python’s buffer protocol, scalar, or sequence of scalars.\n",
    "\n",
    "dlpack is an open standard for exchanging data between deep learning frameworks/libraries. It provides a way to share tensor data in memory between libraries like PyTorch, TensorFlow, MXNet, NumPy, and others without requiring data copying or transformation, ensuring high performance and interoperability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`frombuffer` - Creates a 1D Tensor from an object that implements the Python buffer protocol.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- obj (object) – an object that implements the Python buffer protocol.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from obj.\n",
    "\n",
    "- count (int, optional) – the number of elements to read. Default: -1, which means all elements.\n",
    "\n",
    "- offset (int, optional) – the offset in the buffer. Default: 0.\n",
    "\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient.\n",
    "\n",
    "This function’s behavior is undefined when passed an object implementing the buffer protocol whose data is not on the CPU. Doing so is likely to cause a segmentation fault.\n",
    "\n",
    "This function does not try to infer the dtype (hence, it is not optional). Passing a different dtype than its source may result in unexpected behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = bytearray([0, 0, 128, 63, 0, 0, 0, 64]) \n",
    "\n",
    "t = torch.frombuffer(buffer, dtype=torch.float32)\n",
    "t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zeros` - Returns a tensor filled with zeros, with shape defined by the size argument.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- size (int or tuple of ints) – the shape of the tensor to be created.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from obj.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: None, which causes the device of obj to be used. Or, if obj is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zeros_like` - Returns a tensor filled with zeros, with the same size as input.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- input (torch.Tensor) – the input tensor.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from input.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: None, which causes the device of input to be used. Or, if input is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(torch.randn(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ones` - Returns a tensor filled with ones, with shape defined by the size argument.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- size (int or tuple of ints) – the shape of the tensor to be created.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from obj.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: None, which causes the device of obj to be used. Or, if obj is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ones_like` - Returns a tensor filled with ones, with the same size as input.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- input (torch.Tensor) – the input tensor.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from input.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: None, which causes the device of input to be used. Or, if input is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(torch.randn(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arange` - Returns a 1-D tensor of values from start to end with step size, not including end.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- start (int) – the starting value of the sequence.\n",
    "- end (int) – the ending value of the sequence.\n",
    "- step (int, optional) – the step size between each value in the sequence. Default: 1.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- out (Tensor, optional) – the output tensor.\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_dtype()). If dtype is not given, infer the data type from the other input arguments. If any of start, end, or stop are floating-point, the dtype is inferred to be the default dtype, see get_default_dtype(). Otherwise, the dtype is inferred to be torch.int64.\n",
    "- layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_device()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.5000, 3.0000, 4.5000, 6.0000, 7.5000, 9.0000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 10, step=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linspace` - Returns a 1-D tensor of size steps evenly spaced points from start to end.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- start (float) – the starting value of the sequence.\n",
    "- end (float) – the ending value of the sequence.\n",
    "- steps (int) – the number of steps to take between start and end.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- out (Tensor, optional) – the output tensor.\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_dtype()). If dtype is not given, infer the data type from the other input arguments. If any of start, end, or stop are floating-point, the dtype is inferred to be the default dtype, see get_default_dtype(). Otherwise, the dtype is inferred to be torch.int64.\n",
    "- layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_device()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, 10, steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is similar for 'logspace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(-10, 10, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4.,  16.,  64., 256.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(start=2, end=8, steps=4, base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eye` - Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- n (int) – the number of rows in the output tensor.\n",
    "- m (int, optional) – the number of columns in the output tensor. Default: n.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from obj.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: None, which causes the device of obj to be used. Or, if obj is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `empty` - Returns a tensor filled with uninitialized data.\n",
    "\n",
    "- `empty_like` - Returns an uninitialized tensor with the same size as input.\n",
    "\n",
    "- `empty_strided` - Creates a tensor with specified size and stride, filled with undefined data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`full` - Creates a tensor of specified size filled with fill_value.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- size (int or tuple of ints) – the shape of the tensor to be created.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- fill_value (scalar, optional) – the value to fill the tensor with. Default: 0.\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from fill_value.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: None, which causes the device of fill_value to be used. Or, if fill_value is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5.],\n",
       "        [5., 5., 5.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((2, 3), 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `full_like` function is similar to `full`, but it creates a tensor with the same size as the input tensor and fills it with the specified value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`quantize_per_tensor` - Converts a float tensor to a quantized tensor using given scale and zero point.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- input (torch.Tensor) – the input tensor.\n",
    "- scale (float) – the scale factor for quantization.\n",
    "- zero_point (int) – the zero point for quantization.\n",
    "\n",
    "**Keyword Arguments**\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: None, which causes the datatype of the returned tensor to be inferred from input.\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: None, which causes the device of input to be used. Or, if input is a Python sequence, the current default device will be used.\n",
    "- requires_grad (bool, optional) – whether the returned tensor requires grad. Default: False, which causes the returned tensor not to require a gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  0.,  1.,  2.], size=(4,), dtype=torch.quint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Mixed Precision package - torch.amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic differentiation package - torch.autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding CUDA Memory Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.mps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.xpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.mtia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.backends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed communication package - torch.distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.distributed.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Join Context Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Distributed Elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FullyShardedDataParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Parallelism - torch.distributed.tensor.parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Checkpoint - torch.distributed.checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distributions - torch.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.fx.experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.special"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.overrides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDP Communication Hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed RPC Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Tensors operator coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.__ config __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.__ future __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch._logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchRec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchServe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch on XLA Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-general",
   "language": "python",
   "name": "pytorch-general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
